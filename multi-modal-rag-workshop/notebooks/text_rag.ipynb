{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Textual RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "![RAG Image](../data/rag.png)\n",
    "\n",
    "Retrieval-Augmented Generation (RAG) is an AI technique that combines information retrieval with text generation. Instead of relying solely on a pre-trained language model’s internal knowledge, RAG dynamically retrieves relevant documents from an external knowledge base before generating a response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "![Why RAG Image](../data/why_rag.png)\n",
    "\n",
    "1. **Improved Accuracy:** RAG enhances the factual correctness of generated responses by retrieving up-to-date and domain-specific information, reducing the likelihood of hallucinations (fabricated information).\n",
    "\n",
    "2. **Better Generalization:** Since RAG dynamically retrieves relevant documents, it performs well across various domains without requiring extensive fine-tuning, making it more adaptable to new topics.\n",
    "\n",
    "3. **Reduced Model Size Requirements:** Instead of embedding all knowledge within a large model, RAG leverages external databases, allowing for smaller, more efficient models while maintaining high-quality responses.\n",
    "\n",
    "4. **Enhanced Explainability:** By referencing retrieved documents, RAG provides verifiable sources for its answers, making it more transparent and easier to trust compared to purely generative models.\n",
    "\n",
    "5. **And more...**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "In this exercise, you will learn how to implement a Retrieval-Augmented Generation (RAG) pipeline from scratch, without relying on tools like `langchain`. While `langchain` is a powerful framework that simplifies the development of RAG pipelines, it can sometimes lack flexibility for custom implementations, as it abstracts many components.\n",
    "\n",
    "The different components of the pipeline are:  \n",
    "\n",
    "- **Text extraction from PDFs** – Extract raw text from PDF files to make the content processable.  \n",
    "- **Text chunking** – Break the extracted text into smaller, meaningful segments to improve retrieval efficiency.  \n",
    "- **Embedding of the chunks** – Convert text chunks into numerical representations (embeddings) using a pre-trained model.  \n",
    "- **Storage of the embeddings in a vector store** – Save the embeddings in a specialized database (vector store) to enable fast similarity searches.  \n",
    "- **Relevant chunks retrieval** – Query the vector store to find the most relevant text chunks based on user input.  \n",
    "- **Setting and prompting of the LLM for a RAG** – Structure prompts and configure the language model to integrate retrieved information into its responses.  \n",
    "- **Additional tools for improved retrieval** – Use techniques like query expansion to reformulate user queries for better recall and reciprocal rank fusion to combine results from multiple retrieval methods.  \n",
    "- **Final RAG pipeline implementation** – Integrate all components into a complete system that retrieves relevant information and generates enhanced responses using the language model.  \n",
    "\n",
    "**Note:** To complete this exercise, you need an OpenAI API key, the PDF files, and the necessary libraries installed (see `requirements.txt`).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "import json\n",
    "\n",
    "import chromadb\n",
    "\n",
    "from src.data_classes import Chunk\n",
    "from src.data_processing import SimpleChunker, PDFExtractorAPI\n",
    "from src.embedding import (\n",
    "    OpenAITextEmbeddings,\n",
    "    compute_openai_large_embedding_cost,\n",
    ")\n",
    "from src.vectorstore import (\n",
    "    ChromaDBVectorStore,\n",
    "    VectorStoreRetriever,\n",
    ")\n",
    "from src.llm import OpenAILLM\n",
    "from src.rag import Generator, DefaultRAG, query_expansion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_folder = \"../data\"\n",
    "\n",
    "pdf_files = [\n",
    "    \"Explainable_machine_learning_prediction_of_edema_a.pdf\",\n",
    "    \"Modeling tumor size dynamics based on real‐world electronic health records.pdf\",\n",
    "]\n",
    "example_pdf_file = \"Explainable_machine_learning_prediction_of_edema_a.pdf\"\n",
    "example_pdf_path = os.path.join(data_folder, example_pdf_file)\n",
    "\n",
    "vector_store_collection = \"text_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Example\n",
    "\n",
    "The example uses only `Explainable_machine_learning_prediction_of_edema_a.pdf`. Please, have a quick look at it before starting the exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_question = \"According to SHAP analysis, which factors were the most influential in predicting higher-grade edema (Grade 2+)?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## LLM  \n",
    "\n",
    "The LLM is the core of the RAG system, responsible for generating responses based on the retrieved information. There are many options available on-premise or online, each with different performance, speed, specialized knowledge and cost trade-offs. In this case, we use `gpt-4o-mini`.  \n",
    "\n",
    "This LLM expects input in the form of a list of messages, where each message includes the content and the role of the speaker (e.g., system, user, assistant).  \n",
    "\n",
    "Here is how they are defined here:\n",
    "\n",
    "```python\n",
    "class Roles(str, Enum):\n",
    "    SYSTEM = \"system\"\n",
    "    USER = \"user\"\n",
    "    ASSISTANT = \"assistant\"\n",
    "    TOOL = \"tool\"\n",
    "\n",
    "class LLMMessage(BaseModel):\n",
    "    content: Optional[str] = None\n",
    "    role: Optional[Roles] = None\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI LLM loaded: gpt-4o-mini; temperature: 0.5; seed: 42\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAILLM(temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to SHAP analysis, which factors were the most influential in predicting higher-grade edema (Grade 2+)?\n"
     ]
    }
   ],
   "source": [
    "print(test_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input tokens: 30\n",
      "Total output tokens: 306\n",
      "Total tokens: 336\n",
      "Estimated cost: $0.0002\n"
     ]
    }
   ],
   "source": [
    "answer, price = llm.generate([{\"role\": \"user\", \"content\": test_question}], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SHAP (SHapley Additive exPlanations) analysis is a method used to interpret the output of machine learning models by assigning each feature an importance value for a particular prediction. While I don't have access to specific datasets or studies conducted after October 2023, I can provide general insights into factors that are commonly influential in predicting higher-grade edema (Grade 2+) based on existing literature and clinical knowledge.\n",
      "\n",
      "Typically, the following factors may be influential in predicting higher-grade edema:\n",
      "\n",
      "1. **Clinical Characteristics**: Patient demographics (age, sex), comorbidities (e.g., diabetes, hypertension), and previous medical history can significantly impact edema severity.\n",
      "\n",
      "2. **Treatment Factors**: The type and dosage of medications (e.g., chemotherapy agents, corticosteroids) can play a crucial role. Certain treatments may increase the risk of edema.\n",
      "\n",
      "3. **Radiological Findings**: Imaging characteristics, such as tumor size, location, and the presence of lymphatic involvement, can be predictive of edema severity.\n",
      "\n",
      "4. **Biomarkers**: Levels of specific biomarkers in the blood or tissue may correlate with the degree of edema.\n",
      "\n",
      "5. **Functional Status**: Patient performance status and mobility may influence the development of edema, particularly in cancer patients.\n",
      "\n",
      "6. **Fluid Management**: Factors related to fluid intake and output, including hydration status and renal function, can also contribute to edema severity.\n",
      "\n",
      "If you have specific data or a context in mind, I would be happy to help you analyze or interpret it!\n"
     ]
    }
   ],
   "source": [
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## PDF Text Extraction  \n",
    "\n",
    "The first step in the pipeline is to extract text from the document.  \n",
    "\n",
    "In this exercise, we use the `MinerU` library, which under the hood uses among others `doclayout_yolo` for segmentation. Note that this model is not commercially permissive.\n",
    "\n",
    "The choice of extraction tool should be carefully considered. Depending on the document type and formatting, different methods may be required to preserve text integrity and leverage structural elements such as headings, tables, or metadata for better processing (`pdfplumber` (better for tables), `Tesseract OCR` (for scanned PDFs), ect.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_extractor = PDFExtractorAPI()\n",
    "_, text, _ = data_extractor.extract_text_and_images(example_pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOI: [10.1111/cts.70010](https://doi.org/10.1111/cts.70010)\n",
      "\n",
      "### **ARTICLE**\n",
      "\n",
      "![](_page_0_Picture_4.jpeg)\n",
      "\n",
      "# **Explainable machine learning prediction of edema adverse events in patients treated with tepotinib**\n",
      "\n",
      "**Federico Amato[1](#page-0-0)** | **Rainer Strotmann[2](#page-0-1)** | **Roberto Castell[o1](#page-0-0)** | **Rolf Bruns[2](#page-0-1)** | **Vishal Ghori[3](#page-0-2)** | **Andreas John[e2](#page-0-1)** | **Karin Berghoff[2](#page-0-1)** | **Karthik Venkatakrishna[n4](#page-0-3)** | **Nadia Terranova[5](#page-0-4)**\n",
      "\n",
      "<span id=\"page-0-0\"></span>1 Swiss Data Science Center (EPFL and ETH Zurich), Lausanne, Switzerland\n",
      "\n",
      "<span id=\"page-0-1\"></span>2 The healthcare business of Merck KGaA, Darmstadt, Germany\n",
      "\n",
      "<span id=\"page-0-2\"></span>3 Ares Trading S.A., Eysins, Switzerland, an affiliate of Merck KGaA, Darmstadt, Germany\n",
      "\n",
      "<span id=\"page-0-3\"></span>4 EMD Serono, Billerica, Massachusetts, USA\n",
      "\n",
      "<span id=\"page-0-4\"></span>5 Quantitative Pharmacology, Ares Trading S.A., Lausanne, Swi\n"
     ]
    }
   ],
   "source": [
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Text Chunking  \n",
    "\n",
    "The second step is to split the extracted text into smaller chunks, which will later be embedded and retrieved efficiently.  \n",
    "\n",
    "In this exercise, we use a simple heuristic approach: the text is split iteratively—first by heading levels (`#`), then by line breaks (`\\n`), and finally by sentence (`.`). Splitting only occurs if the resulting chunk exceeds a predefined length. However, more advanced techniques exist, such as **semantic chunking** (which splits based on meaning rather than syntax) or **agentic chunking** (which dynamically adapts chunk sizes based on context).  \n",
    "\n",
    "Each chunk is enriched with metadata, including:  \n",
    "- **Source file** – The document from which the chunk originates.  \n",
    "- **Chunk counter** – The position of the chunk within the file.  \n",
    "- **Unique identifier (`chunk_id`)** – Ensures each chunk can be referenced independently.  \n",
    "\n",
    "Additional metadata could be included to enable more refined filtering and retrieval strategies.  \n",
    "\n",
    "Here, our chunks are defined as:\n",
    "```python\n",
    "class Chunk(BaseModel):\n",
    "    chunk_id: int\n",
    "    content: str\n",
    "    metadata: dict = Field(default_factory=dict)\n",
    "    score: Optional[float] = None\n",
    "```  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_metadata = {\"source_text\": example_pdf_file}\n",
    "\n",
    "text_chunker = SimpleChunker(max_chunk_size=1000)\n",
    "\n",
    "chunks = text_chunker.chunk_text(text, file_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chunk(chunk_id=0, content='DOI: [10.1111/cts.70010](https://doi.org/10.1111/cts.70010) ### **ARTICLE** ![](_page_0_Picture_4.jpeg) # **Explainable machine learning prediction of edema adverse events in patients treated with tepotinib** **Federico Amato[1](#page-0-0)** | **Rainer Strotmann[2](#page-0-1)** | **Roberto Castell[o1](#page-0-0)** | **Rolf Bruns[2](#page-0-1)** | **Vishal Ghori[3](#page-0-2)** | **Andreas John[e2](#page-0-1)** | **Karin Berghoff[2](#page-0-1)** | **Karthik Venkatakrishna[n4](#page-0-3)** | **Nadia Terranova[5](#page-0-4)** <span id=\"page-0-0\"></span>1 Swiss Data Science Center (EPFL and ETH Zurich), Lausanne, Switzerland <span id=\"page-0-1\"></span>2 The healthcare business of Merck KGaA, Darmstadt, Germany <span id=\"page-0-2\"></span>3 Ares Trading S.A., Eysins, Switzerland, an affiliate of Merck KGaA, Darmstadt, Germany <span id=\"page-0-3\"></span>4 EMD Serono, Billerica, Massachusetts, USA', metadata={'source_text': 'Explainable_machine_learning_prediction_of_edema_a.pdf', 'document_chunk_id': 0}, data_type=<DataType.TEXT: 'text'>, score=None)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(chunks))\n",
    "chunks[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Embedding Model  \n",
    "\n",
    "Once the text is split into chunks, each chunk is converted into a numerical representation (embedding) that captures its meaning.  \n",
    "\n",
    "Here, we use OpenAI’s `text-embedding-3-large`, but other options exist, each with different trade-offs in on-premise vs online, accuracy, speed, and cost. The choice of model depends on the specific needs of the retrieval task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 13665\n",
      "Estimated cost: $0.0018\n"
     ]
    }
   ],
   "source": [
    "_ = compute_openai_large_embedding_cost(chunks, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_model = OpenAITextEmbeddings()\n",
    "embeddings = embedding_model.get_embedding([chunk.content for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62, 3072)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.03147229,  0.00638142, -0.01330947, ...,  0.00983923,\n",
       "        0.00326732, -0.00159018], shape=(3072,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(embeddings.shape)\n",
    "embeddings[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Vector Store and Retriever  \n",
    "\n",
    "After embedding the chunks, they need to be stored for efficient retrieval. The choice of vector store depends on factors like accuracy, speed, and filtering options. In this exercise, we use `ChromaDB`.  \n",
    "\n",
    "The next step is retrieving the most relevant chunks based on a query. In this implementation, the retriever uses only embeddings (sparse search). However, in some cases, dense search methods like BM25 or hybrid approaches combining both sparse and dense search can be used for better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vector_store = ChromaDBVectorStore(vector_store_collection)\n",
    "vector_store.insert_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to SHAP analysis, which factors were the most influential in predicting higher-grade edema (Grade 2+)?\n"
     ]
    }
   ],
   "source": [
    "print(test_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'chunk_id': '39',\n",
       "   'score': 0.5417101979255676,\n",
       "   'chunk': Chunk(chunk_id=39, content='Points are colored based on the edema grade at the following safety visit. SHAP, Shapley Additive exPlanations. with higher grades of edema, particularly grade 2+. On the other hand, for higher albumin levels the corresponding SHAP values are mostly negative and ranging from 0 to −0.5, suggesting a reduced risk of edema of grade 2+. The association between age greater than 70years and an increased likelihood of edemas of grades 2+ was also confirmed. Additionally, for all ages, higher SHAP values were assigned to patients who experienced edemas, particularly of grade 2+. Finally, within low ranges of cumulated dose in the interval [ *t* − 14 days, *t* ] normalized over 14days, higher SHAP values were assigned to samples corresponding to edemas of grades 2+. This could reflect the tendency to adjust administered doses in those cases where the risk of edema was identified. # **DISCUSSION**', metadata={'source_text': 'Explainable_machine_learning_prediction_of_edema_a.pdf', 'document_chunk_id': 39}, data_type=<DataType.TEXT: 'text'>, score=None)},\n",
       "  {'chunk_id': '32',\n",
       "   'score': 0.6072132587432861,\n",
       "   'chunk': Chunk(chunk_id=32, content='Consistently with the above sensitivity analysis, past current edema grade was found to be the most influential input, particularly if a same grade persisted to the following safety visit. The exposure-derived features were also informative for the model probability predictions. Albumin was found as the most informative time-varying covariate, especially for predicting edemas of grades 2+. Figure [3](#page-7-1) illustrates the contribution of the input variables toward the predicted probability of edemas of grades 2+. The analysis reveals that the current edema grade is the most informative input, as patients with a history of edemas of grades 2+ are considered highly likely to experience the same grade in the future. Interestingly, albumin once again emerges as the most informative among the longitudinal covariates, with lower levels associated <span id=\"page-6-0\"></span>', metadata={'source_text': 'Explainable_machine_learning_prediction_of_edema_a.pdf', 'document_chunk_id': 32}, data_type=<DataType.TEXT: 'text'>, score=None)},\n",
       "  {'chunk_id': '42',\n",
       "   'score': 0.6111927032470703,\n",
       "   'chunk': Chunk(chunk_id=42, content='The presence of such input is ensuring high model performances when predicting persistence of a given edema grade. The sensitivity analysis to the inclusion of this input revealed a decline in the mean cross-validation F1 score of ~0.350 when it was removed as a candidate predictor. However, the use of Isotonic Regressions ensures the estimations of correctly calibrated probabilities. For instance, while low predicted probabilities, for example, for edemas of grade 2+, might lead to a classification error, they can still provide valuable details on existing risk of occurrence of an adverse event (Figure [S5\\\\)](#page-11-0). Moreover, sensitivity analysis together with the SHAP importance highlighted interesting patterns with respect to the exposure-related features. Referencing Figure [3](#page-7-1), lower values of the dose [ *t* − 14 days, *t* ] are associated with a decreased probability of edema of grades 2+ at subsequent visits.', metadata={'source_text': 'Explainable_machine_learning_prediction_of_edema_a.pdf', 'document_chunk_id': 42}, data_type=<DataType.TEXT: 'text'>, score=None)},\n",
       "  {'chunk_id': '37',\n",
       "   'score': 0.6610822677612305,\n",
       "   'chunk': Chunk(chunk_id=37, content='![](_page_7_Figure_0.jpeg) <span id=\"page-7-0\"></span>**FIGURE 2** Global input importance via mean SHAP values. Ranking of the model input for the most influential to the less influential for the model. The y-axis indicates the average change in the predicted probability of edema by grade, on average across the entire test set. SHAP, Shapley Additive exPlanations. <span id=\"page-7-1\"></span>**FIGURE 3** SHAP values – contribution of the inputs toward the predicted probabilities of edemas of grade 2+. List of the eight most influential inputs with respect to the predicted probabilities of edemas of grades 2+. Each point on the plot is a SHAP value for a covariate at a specific patient visit. The position on the y-axis indicates the covariate importance and on the x-axis the impact on the predicted probability. Color represents the value of the covariate. SHAP, Shapley Additive exPlanations. with an increase in the predicted probability of edemas of grades 2+.', metadata={'source_text': 'Explainable_machine_learning_prediction_of_edema_a.pdf', 'document_chunk_id': 37}, data_type=<DataType.TEXT: 'text'>, score=None)},\n",
       "  {'chunk_id': '45',\n",
       "   'score': 0.7390602231025696,\n",
       "   'chunk': Chunk(chunk_id=45, content=\"Advanced age was also found as predictive of edemas of grade 2+, in agreement with current knowledge of the investigated adverse event behavior, for which age is known to be a risk factor independently from drug exposure.[36,37](#page-11-11) Finally, the time until the next visit, used to inform the model about the forecasting horizon, was also informative. However, this input should be seen as a factor reflecting the deteriorating status of patients, as changes in medical condition could prompt clinicians to schedule short-term (re-)assessment visits. One of the primary challenges encountered in this study's classification setting was the unbalanced representation of different edema grades in the data. To overcome this issue, the model was set up to produce a probability for each edema grade of any new patient instance. When dealing with unbalanced data, such probabilities can be small, which is not a problem as long as they are accurate.\", metadata={'source_text': 'Explainable_machine_learning_prediction_of_edema_a.pdf', 'document_chunk_id': 45}, data_type=<DataType.TEXT: 'text'>, score=None)}]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = VectorStoreRetriever(embedding_model, vector_store)\n",
    "results = retriever.retrieve(test_question, 5)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Generator  \n",
    "\n",
    "Once the LLM is set up, a specific prompt needs to be defined for the RAG system. This prompt must include the retrieved chunks as context. The prompt has to be adapted to each specific project.\n",
    "\n",
    "In addition to the basic prompt, we incorporate **prompt engineering** by asking the LLM to justify its answer. The model is also instructed to indicate which chunks were most relevant in forming its response, improving **interpretability**, and to provide the answer in **JSON format** for easier data management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant, and your task is to answer questions using relevant documents. Please first think step-by-step by mentioning which documents you used and then answer the question. Organize your output in a json formatted as dict{\"step_by_step_thinking\": Str(explanation), \"document_used\": List(integers), \"answer\": Str{answer}}. Your responses will be read by someone without specialized knowledge, so please have a definite and concise answer.\n"
     ]
    }
   ],
   "source": [
    "default_system_prompt = \"\"\"You are a helpful assistant, and your task is to answer questions using relevant documents. Please first think step-by-step by mentioning which documents you used and then answer the question. Organize your output in a json formatted as dict{\"step_by_step_thinking\": Str(explanation), \"document_used\": List(integers), \"answer\": Str{answer}}. Your responses will be read by someone without specialized knowledge, so please have a definite and concise answer.\"\"\"\n",
    "print(default_system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here are the relevant DOCUMENTS:\n",
      "{context}\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Here is the USER QUESTION:\n",
      "{query}\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Please think step-by-step and generate your output in json:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "default_rag_template = \"\"\"\n",
    "Here are the relevant DOCUMENTS:\n",
    "{context}\n",
    "\n",
    "--------------------------------------------\n",
    "\n",
    "Here is the USER QUESTION:\n",
    "{query}\n",
    "\n",
    "--------------------------------------------\n",
    "\n",
    "Please think step-by-step and generate your output in json:\n",
    "\"\"\"\n",
    "print(default_rag_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to SHAP analysis, which factors were the most influential in predicting higher-grade edema (Grade 2+)?\n"
     ]
    }
   ],
   "source": [
    "print(test_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = Generator(\n",
    "    llm, system_prompt=default_system_prompt, rag_template=default_rag_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant, and your task is to answer questions using relevant documents. Please first think step-by-step by mentioning which documents you used and then answer the question. Organize your output in a json formatted as dict{\"step_by_step_thinking\": Str(explanation), \"document_used\": List(integers), \"answer\": Str{answer}}. Your responses will be read by someone without specialized knowledge, so please have a definite and concise answer.\n",
      "\n",
      "Here are the relevant DOCUMENTS:\n",
      "\n",
      "\n",
      "Document 1: \n",
      "Points are colored based on the edema grade at the following safety visit. SHAP, Shapley Additive exPlanations. with higher grades of edema, particularly grade 2+. On the other hand, for higher albumin levels the corresponding SHAP values are mostly negative and ranging from 0 to −0.5, suggesting a reduced risk of edema of grade 2+. The association between age greater than 70years and an increased likelihood of edemas of grades 2+ was also confirmed. Additionally, for all ages, higher SHAP values were assigned to patients who experienced edemas, particularly of grade 2+. Finally, within low ranges of cumulated dose in the interval [ *t* − 14 days, *t* ] normalized over 14days, higher SHAP values were assigned to samples corresponding to edemas of grades 2+. This could reflect the tendency to adjust administered doses in those cases where the risk of edema was identified. # **DISCUSSION**\n",
      "\n",
      "Document 2: \n",
      "DATE: 1999.12.02\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Here is the USER QUESTION:\n",
      "According to SHAP analysis, which factors were the most influential in predicting higher-grade edema (Grade 2+)?\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Please think step-by-step and generate your output in json:\n",
      "\n",
      "Total input tokens: 379\n",
      "Total output tokens: 162\n",
      "Total tokens: 541\n",
      "Estimated cost: $0.0002\n"
     ]
    }
   ],
   "source": [
    "answer, cost = generator.generate(\n",
    "    history=[],\n",
    "    query=test_question,\n",
    "    chunks=[\n",
    "        results[0][0][\"chunk\"],\n",
    "        Chunk(chunk_id=1, content=\"DATE: 1999.12.02\", metadata={}),\n",
    "    ],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"step_by_step_thinking\": \"I reviewed Document 1 to identify the factors influencing higher-grade edema (Grade 2+). The document mentions that higher edema grades correlate with certain factors, particularly age greater than 70 years, higher SHAP values for patients with edema, and lower albumin levels. Additionally, it discusses the influence of cumulated dose within a specific time frame. Therefore, the most influential factors in predicting higher-grade edema include age, albumin levels, and cumulated dose adjustments.\",\n",
      "  \"document_used\": [1],\n",
      "  \"answer\": \"The most influential factors in predicting higher-grade edema (Grade 2+) according to SHAP analysis are age greater than 70 years, lower albumin levels, and higher SHAP values assigned to patients experiencing edema.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(answer.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## RAG Tools  \n",
    "\n",
    "There are several methods to improve the efficiency of a RAG pipeline, such as query contextualization, query reformulation, re-ranking, query expansion, etc.\n",
    "\n",
    "In this notebook, we implement **query expansion** to enhance retrieval and apply **reciprocal rank fusion** to optimize the ranking of chunks when multiple queries are involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_expansion_system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are a focused assistant designed to generate multiple, relevant search queries based solely on a single input query. Your task is to produce a list of these queries in English, without adding any further explanations or information.\",\n",
    "}\n",
    "\n",
    "query_expansion_template_query = \"\"\"\n",
    "        Generate multiple search queries related to: {query}, and translate them in english if they are not already in english. Only output {expansion_number} queries in english.\n",
    "        OUTPUT ({expansion_number} queries):\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to SHAP analysis, which factors were the most influential in predicting higher-grade edema (Grade 2+)?\n"
     ]
    }
   ],
   "source": [
    "print(test_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input tokens: 113\n",
      "Total output tokens: 89\n",
      "Total tokens: 202\n",
      "Estimated cost: $0.0001\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['1. What factors influence higher-grade edema according to SHAP analysis?  ',\n",
       " '2. How does SHAP analysis determine the predictors of Grade 2+ edema?  ',\n",
       " '3. Which variables are most significant in predicting higher-grade edema using SHAP?  ',\n",
       " '4. What insights does SHAP analysis provide on factors affecting Grade 2+ edema?  ',\n",
       " '5. Can SHAP analysis identify key predictors for severe edema (Grade 2+)?']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer, cost = query_expansion(\n",
    "    test_question,\n",
    "    llm,\n",
    "    query_expansion_system_message,\n",
    "    template_query_expansion=query_expansion_template_query,\n",
    "    expansion_number=5,\n",
    ")\n",
    "\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## RAG  \n",
    "\n",
    "Finally, the RAG pipeline is defined by integrating all the previously discussed components into a unified process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rag = DefaultRAG(\n",
    "    llm=llm,\n",
    "    text_embedding_model=embedding_model,\n",
    "    text_vector_store=vector_store,\n",
    "    generator=generator,\n",
    "    query_expansion_system_message=query_expansion_system_message,\n",
    "    query_expansion_template_query=query_expansion_template_query,\n",
    "    params={\"top_k\": 5, \"number_query_expansion\": 3},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to SHAP analysis, which factors were the most influential in predicting higher-grade edema (Grade 2+)?\n"
     ]
    }
   ],
   "source": [
    "print(test_question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total input tokens: 113\n",
      "Total output tokens: 59\n",
      "Total tokens: 172\n",
      "Estimated cost: $0.0001\n",
      "Query expansion cost: 0.0001\n",
      "Expanded queries:\n",
      "1. What factors influence higher-grade edema (Grade 2+) according to SHAP analysis?  \n",
      "2. How does SHAP analysis identify key predictors for Grade 2+ edema?  \n",
      "3. Which variables are most significant in predicting Grade 2+ edema using SHAP analysis?\n",
      "\n",
      "You are a helpful assistant, and your task is to answer questions using relevant documents. Please first think step-by-step by mentioning which documents you used and then answer the question. Organize your output in a json formatted as dict{\"step_by_step_thinking\": Str(explanation), \"document_used\": List(integers), \"answer\": Str{answer}}. Your responses will be read by someone without specialized knowledge, so please have a definite and concise answer.\n",
      "\n",
      "Here are the relevant DOCUMENTS:\n",
      "\n",
      "\n",
      "Document 1: \n",
      "Points are colored based on the edema grade at the following safety visit. SHAP, Shapley Additive exPlanations. with higher grades of edema, particularly grade 2+. On the other hand, for higher albumin levels the corresponding SHAP values are mostly negative and ranging from 0 to −0.5, suggesting a reduced risk of edema of grade 2+. The association between age greater than 70years and an increased likelihood of edemas of grades 2+ was also confirmed. Additionally, for all ages, higher SHAP values were assigned to patients who experienced edemas, particularly of grade 2+. Finally, within low ranges of cumulated dose in the interval [ *t* − 14 days, *t* ] normalized over 14days, higher SHAP values were assigned to samples corresponding to edemas of grades 2+. This could reflect the tendency to adjust administered doses in those cases where the risk of edema was identified. # **DISCUSSION**\n",
      "\n",
      "Document 2: \n",
      "![](_page_7_Figure_0.jpeg) <span id=\"page-7-0\"></span>**FIGURE 2** Global input importance via mean SHAP values. Ranking of the model input for the most influential to the less influential for the model. The y-axis indicates the average change in the predicted probability of edema by grade, on average across the entire test set. SHAP, Shapley Additive exPlanations. <span id=\"page-7-1\"></span>**FIGURE 3** SHAP values – contribution of the inputs toward the predicted probabilities of edemas of grade 2+. List of the eight most influential inputs with respect to the predicted probabilities of edemas of grades 2+. Each point on the plot is a SHAP value for a covariate at a specific patient visit. The position on the y-axis indicates the covariate importance and on the x-axis the impact on the predicted probability. Color represents the value of the covariate. SHAP, Shapley Additive exPlanations. with an increase in the predicted probability of edemas of grades 2+.\n",
      "\n",
      "Document 3: \n",
      "The presence of such input is ensuring high model performances when predicting persistence of a given edema grade. The sensitivity analysis to the inclusion of this input revealed a decline in the mean cross-validation F1 score of ~0.350 when it was removed as a candidate predictor. However, the use of Isotonic Regressions ensures the estimations of correctly calibrated probabilities. For instance, while low predicted probabilities, for example, for edemas of grade 2+, might lead to a classification error, they can still provide valuable details on existing risk of occurrence of an adverse event (Figure [S5\\)](#page-11-0). Moreover, sensitivity analysis together with the SHAP importance highlighted interesting patterns with respect to the exposure-related features. Referencing Figure [3](#page-7-1), lower values of the dose [ *t* − 14 days, *t* ] are associated with a decreased probability of edema of grades 2+ at subsequent visits.\n",
      "\n",
      "Document 4: \n",
      "The second objective of the study was the identification of the factors predicting edema occurrence and evolution over time. The Shapley Additive exPlanations (SHAP) method was used to investigate the role different factors have toward a specific estimation of edema occurrence obtained via the best predictive model, both at population and patient level. The use of this approach overcomes the lack of explainability of ML models, which approximate complex nonlinear functions from data in a not straightforwardly interpretable manner.[20,21](#page-10-11) # **METHODS** # **Clinical data** Data from 612 patients enrolled in five Phase I/II clinical studies with tepotinib were collected (NCT01014936, NCT01832506, NCT01988493, NCT02115373, VISION – NCT02864992).\n",
      "\n",
      "Document 5: \n",
      "Consistently with the above sensitivity analysis, past current edema grade was found to be the most influential input, particularly if a same grade persisted to the following safety visit. The exposure-derived features were also informative for the model probability predictions. Albumin was found as the most informative time-varying covariate, especially for predicting edemas of grades 2+. Figure [3](#page-7-1) illustrates the contribution of the input variables toward the predicted probability of edemas of grades 2+. The analysis reveals that the current edema grade is the most informative input, as patients with a history of edemas of grades 2+ are considered highly likely to experience the same grade in the future. Interestingly, albumin once again emerges as the most informative among the longitudinal covariates, with lower levels associated <span id=\"page-6-0\"></span>\n",
      "\n",
      "Document 6: \n",
      "Moreover, age impact on predictions appears to have an evident pattern, with older subjects associated with an increased probability of edemas of grade 2+. Figure [4](#page-8-0) illustrates the relationship between albumin, age, the [ *t* − 14 days, *t* ] cumulated dose normalized over 14days, and their corresponding SHAP values for predicting the likelihood of edemas of grades 2+. For lower albumin levels, positive SHAP contributions between 0 and 0.5 are consistently assigned, signifying an increased risk of developing edema of grade 2+. Notably, very low albumin values are predominantly associated ![](_page_8_Figure_1.jpeg) <span id=\"page-8-0\"></span>**FIGURE 4** Interactions between covariate values and corresponding SHAP values. Scatterplot of the covariate value against its corresponding SHAP value for albumin, age, and cumulated dose over 2weeks prior to the time at which prediction is performed. Each point corresponds to a specific patient visit.\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Here is the USER QUESTION:\n",
      "According to SHAP analysis, which factors were the most influential in predicting higher-grade edema (Grade 2+)?\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Please think step-by-step and generate your output in json:\n",
      "\n",
      "Total input tokens: 1395\n",
      "Total output tokens: 231\n",
      "Total tokens: 1626\n",
      "Estimated cost: $0.0003\n"
     ]
    }
   ],
   "source": [
    "answer, sources, cost = rag.execute(test_question, {}, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"step_by_step_thinking\": \"To determine the most influential factors in predicting higher-grade edema (Grade 2+), I analyzed the relevant documents. Document 1 indicates that higher albumin levels are associated with a reduced risk of edema, while age greater than 70 years correlates with an increased likelihood of higher-grade edemas. Document 2 highlights the ranking of inputs based on SHAP values, suggesting that certain covariates significantly impact the predicted probabilities of edemas of grade 2+. Document 5 emphasizes that past current edema grade is the most influential input, especially if the same grade persists. Additionally, Document 6 confirms that older age increases the probability of higher-grade edema. Therefore, the primary influential factors identified are past edema grade, age, and albumin levels.\",\n",
      "   \"document_used\": [\n",
      "      1,\n",
      "      2,\n",
      "      5,\n",
      "      6\n",
      "   ],\n",
      "   \"answer\": \"The most influential factors in predicting higher-grade edema (Grade 2+) according to SHAP analysis are past current edema grade, age (especially being over 70 years), and albumin levels (with lower levels increasing risk).\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(answer, indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "{'chunk_id': '39', 'chunk': Chunk(chunk_id=39, content='Points are colored based on the edema grade at the following safety visit. SHAP, Shapley Additive exPlanations. with higher grades of edema, particularly grade 2+. On the other hand, for higher albumin levels the corresponding SHAP values are mostly negative and ranging from 0 to −0.5, suggesting a reduced risk of edema of grade 2+. The association between age greater than 70years and an increased likelihood of edemas of grades 2+ was also confirmed. Additionally, for all ages, higher SHAP values were assigned to patients who experienced edemas, particularly of grade 2+. Finally, within low ranges of cumulated dose in the interval [ *t* − 14 days, *t* ] normalized over 14days, higher SHAP values were assigned to samples corresponding to edemas of grades 2+. This could reflect the tendency to adjust administered doses in those cases where the risk of edema was identified. # **DISCUSSION**', metadata={'source_text': 'Explainable_machine_learning_prediction_of_edema_a.pdf', 'document_chunk_id': 39}, data_type=<DataType.TEXT: 'text'>, score=None), 'fused_score': 0.04620592054390803, 'average_original_score': 0.5387637217839559}\n"
     ]
    }
   ],
   "source": [
    "# The documents retrieved by the retriever:\n",
    "print(len(sources))\n",
    "print(sources[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0004002\n"
     ]
    }
   ],
   "source": [
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Exercises\n",
    "\n",
    "The different blocks are redefined below, and a new pipeline is created that uses both PDFs.\n",
    "\n",
    "1. Quickly go through the code and the notebook above to ensure you understand how each block works.\n",
    "2. Answer the following questions related to `Explainable_machine_learning_prediction_of_edema_a.pdf` and analyze the answers:\n",
    "   1. \"What was identified as the most important predictor for edema occurrence?\"\n",
    "   2. \"Which machine learning algorithm performed best for predicting edema, and what was its F1 score?\"\n",
    "   3. \"How did cumulative tepotinib dose impact edema predictions, and what insights did SHAP provide about this relationship?\"\n",
    "   4. Propose your own question.\n",
    "3. Review the `Modeling tumor size dynamics based on real‐world electronic health records.pdf` and come up with a question. Ask it and analyze the answer, confirm that the retriever uses relevant chunks from this source.\n",
    "4. Discuss how the pipeline could be improved to achieve better answers. If time permits, implement those changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_extractor = PDFExtractorAPI()\n",
    "text_chunker = SimpleChunker(max_chunk_size=1000)\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for pdf_file in pdf_files:\n",
    "    pdf_path = os.path.join(data_folder, pdf_file)\n",
    "    _, text, _ = data_extractor.extract_text_and_images(pdf_path)\n",
    "    chunks_curr = text_chunker.chunk_text(text, {\"source_text\": pdf_file})\n",
    "    chunks.extend(chunks_curr)\n",
    "    print(len(chunks))\n",
    "\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total tokens: 27879\n",
      "Estimated cost: $0.0036\n"
     ]
    }
   ],
   "source": [
    "_ = compute_openai_large_embedding_cost(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "embedding_model = OpenAITextEmbeddings()\n",
    "embeddings = embedding_model.get_embedding([chunk.content for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Reset previous\n",
    "client = chromadb.Client()\n",
    "client.delete_collection(vector_store_collection)\n",
    "\n",
    "# Create new one\n",
    "vector_store = ChromaDBVectorStore(vector_store_collection)\n",
    "vector_store.insert_documents(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI LLM loaded: gpt-4o-mini; temperature: 1.0; seed: 42\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAILLM(temperature=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant, and your task is to answer questions using relevant documents. Please first think step-by-step by mentioning which documents you used and then answer the question. Organize your output in a json formatted as dict{\"step_by_step_thinking\": Str(explanation), \"document_used\": List(integers), \"answer\": Str{answer}}. Your responses will be read by someone without specialized knowledge, so please have a definite and concise answer.\n"
     ]
    }
   ],
   "source": [
    "system_prompt = \"\"\"You are a helpful assistant, and your task is to answer questions using relevant documents. Please first think step-by-step by mentioning which documents you used and then answer the question. Organize your output in a json formatted as dict{\"step_by_step_thinking\": Str(explanation), \"document_used\": List(integers), \"answer\": Str{answer}}. Your responses will be read by someone without specialized knowledge, so please have a definite and concise answer.\"\"\"\n",
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Here are the relevant DOCUMENTS:\n",
      "{context}\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Here is the USER QUESTION:\n",
      "{query}\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Please think step-by-step and generate your output in json:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rag_template = \"\"\"\n",
    "Here are the relevant DOCUMENTS:\n",
    "{context}\n",
    "\n",
    "--------------------------------------------\n",
    "\n",
    "Here is the USER QUESTION:\n",
    "{query}\n",
    "\n",
    "--------------------------------------------\n",
    "\n",
    "Please think step-by-step and generate your output in json:\n",
    "\"\"\"\n",
    "print(rag_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "query_expansion_system_message = {\n",
    "    \"role\": \"system\",\n",
    "    \"content\": \"You are a focused assistant designed to generate multiple, relevant search queries based solely on a single input query. Your task is to produce a list of these queries in English, without adding any further explanations or information.\",\n",
    "}\n",
    "\n",
    "query_expansion_template_query = \"\"\"\n",
    "        Generate multiple search queries related to: {query}, and translate them in english if they are not already in english. Only output {expansion_number} queries in english.\n",
    "        OUTPUT ({expansion_number} queries):\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "generator = Generator(llm, system_prompt=system_prompt, rag_template=rag_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rag = DefaultRAG(\n",
    "    llm=llm,\n",
    "    text_embedding_model=embedding_model,\n",
    "    text_vector_store=vector_store,\n",
    "    generator=generator,\n",
    "    query_expansion_system_message=query_expansion_system_message,\n",
    "    query_expansion_template_query=query_expansion_template_query,\n",
    "    params={\"top_k\": 1, \"number_query_expansion\": 0},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a helpful assistant, and your task is to answer questions using relevant documents. Please first think step-by-step by mentioning which documents you used and then answer the question. Organize your output in a json formatted as dict{\"step_by_step_thinking\": Str(explanation), \"document_used\": List(integers), \"answer\": Str{answer}}. Your responses will be read by someone without specialized knowledge, so please have a definite and concise answer.\n",
      "\n",
      "Here are the relevant DOCUMENTS:\n",
      "\n",
      "\n",
      "Document 1: \n",
      "<span id=\"page-11-1\"></span>Additional supporting information can be found online in the Supporting Information section at the end of this article. **How to cite this article:** Amato F, Strotmann R, Castello R, et al. Explainable machine learning prediction of edema adverse events in patients treated with tepotinib. *Clin Transl Sci*. 2024;17:e70010. doi[:10.1111/cts.70010](https://doi.org/10.1111/cts.70010)\n",
      "\n",
      "Document 2: \n",
      "DOI: [10.1111/cts.70010](https://doi.org/10.1111/cts.70010) ### **ARTICLE** ![](_page_0_Picture_4.jpeg) # **Explainable machine learning prediction of edema adverse events in patients treated with tepotinib** **Federico Amato[1](#page-0-0)** | **Rainer Strotmann[2](#page-0-1)** | **Roberto Castell[o1](#page-0-0)** | **Rolf Bruns[2](#page-0-1)** | **Vishal Ghori[3](#page-0-2)** | **Andreas John[e2](#page-0-1)** | **Karin Berghoff[2](#page-0-1)** | **Karthik Venkatakrishna[n4](#page-0-3)** | **Nadia Terranova[5](#page-0-4)** <span id=\"page-0-0\"></span>1 Swiss Data Science Center (EPFL and ETH Zurich), Lausanne, Switzerland <span id=\"page-0-1\"></span>2 The healthcare business of Merck KGaA, Darmstadt, Germany <span id=\"page-0-2\"></span>3 Ares Trading S.A., Eysins, Switzerland, an affiliate of Merck KGaA, Darmstadt, Germany <span id=\"page-0-3\"></span>4 EMD Serono, Billerica, Massachusetts, USA\n",
      "\n",
      "Document 3: \n",
      "*Clinical and Translational Science* published by Wiley Periodicals LLC on behalf of American Society for Clinical Pharmacology and Therapeutics. dose modifications in reducing this AE, exploring its relationship with potential prognostic factors. ### **WHAT QUESTION DID THIS STUDY ADDRESS?** Are there baseline and time-varying factors to support the identification of higher likelihood of edema occurrence in patients receiving tepotinib treatment? ### **WHAT DOES THIS STUDY ADD TO OUR KNOWLEDGE?** This study assesses 54 covariates as predictors of edema using ML. Explainability tools investigate the relationship between input covariates and predicted outcomes. The identified drivers align with the existing knowledge of the investigated AE behavior. ### **HOW MIGHT THIS CHANGE DRUG DISCOVERY, DEVELOPMENT, AND/OR THERAPEUTICS?**\n",
      "\n",
      "Document 4: \n",
      "Murphy KP. *Machine Learning – A Probabilistic Perspective*. The MIT Press; 2012. - 8. Sibieude E, Khandelwal A, Girard P, Hesthaven JS, Terranova N. Population pharmacokinetic model selection assisted by machine learning. *J Pharmacokinet Pharmacodyn*. 2022;49:257-270. - <span id=\"page-10-5\"></span>9. Baker RE, Peña JM, Jayamohan J, Jérusalem A. Mechanistic models versus machine learning, a fight worth fighting for the biological community? *Biol Lett*. 2018;14:20170660. - <span id=\"page-10-6\"></span>10. Xiong W, Hietala SF, Nyberg J, et al. Exposure-response analyses for the MET inhibitor tepotinib including patients in the pivotal VISION trial: support for dosage recommendations. *Cancer Chemother Pharmacol*. 2022;90:53-69. - <span id=\"page-10-7\"></span>11. Gao CF, Woude GF. Vande HGF/SF-met signaling in tumor progression. *Cell Res*. 2005;15:49-51. - 12. Birchmeier C, Birchmeier W, Gherardi E, Woude GF. Vande met, metastasis, motility and more. *Nat Rev Mol Cell Biol*.\n",
      "\n",
      "Document 5: \n",
      "![](_page_7_Figure_0.jpeg) <span id=\"page-7-0\"></span>**FIGURE 2** Global input importance via mean SHAP values. Ranking of the model input for the most influential to the less influential for the model. The y-axis indicates the average change in the predicted probability of edema by grade, on average across the entire test set. SHAP, Shapley Additive exPlanations. <span id=\"page-7-1\"></span>**FIGURE 3** SHAP values – contribution of the inputs toward the predicted probabilities of edemas of grade 2+. List of the eight most influential inputs with respect to the predicted probabilities of edemas of grades 2+. Each point on the plot is a SHAP value for a covariate at a specific patient visit. The position on the y-axis indicates the covariate importance and on the x-axis the impact on the predicted probability. Color represents the value of the covariate. SHAP, Shapley Additive exPlanations. with an increase in the predicted probability of edemas of grades 2+.\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Here is the USER QUESTION:\n",
      "Here goes my amazing question!\n",
      "\n",
      "--------------------------------------------\n",
      "\n",
      "Please think step-by-step and generate your output in json:\n",
      "\n",
      "Total input tokens: 1312\n",
      "Total output tokens: 204\n",
      "Total tokens: 1516\n",
      "Estimated cost: $0.0003\n"
     ]
    }
   ],
   "source": [
    "answer, sources, cost = rag.execute(\n",
    "    \"Here goes my amazing question!\",\n",
    "    {},\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"step_by_step_thinking\": \"I analyzed the given documents to answer the question regarding the machine learning study on edema in patients treated with tepotinib. I focused particularly on Document 3, which discusses the specific study objectives, the factors evaluated (54 covariates), and the use of machine learning to assess predictors of edema. I also looked at Document 2 for article citation and additional context. Document 5 provides insights into the SHAP (Shapley Additive Explanations) values, which indicate how the model interprets the importance of different inputs in predicting edema. This combination of information helps in understanding the machine learning approach taken in the study.\",\n",
      "   \"document_used\": [\n",
      "      2,\n",
      "      3,\n",
      "      5\n",
      "   ],\n",
      "   \"answer\": \"The study on explainable machine learning predicts edema adverse events in patients treated with tepotinib by assessing 54 covariates as potential predictors. It uses SHAP values to determine the influence of these inputs on the likelihood of developing edema.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(answer, indent=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "{'chunk_id': '61', 'chunk': Chunk(chunk_id=61, content='<span id=\"page-11-1\"></span>Additional supporting information can be found online in the Supporting Information section at the end of this article. **How to cite this article:** Amato F, Strotmann R, Castello R, et al. Explainable machine learning prediction of edema adverse events in patients treated with tepotinib. *Clin Transl Sci*. 2024;17:e70010. doi[:10.1111/cts.70010](https://doi.org/10.1111/cts.70010)', metadata={'source_text': 'Explainable_machine_learning_prediction_of_edema_a.pdf', 'document_chunk_id': 61}, data_type=<DataType.TEXT: 'text'>, score=None), 'fused_score': 0.016129032258064516, 'average_original_score': 1.6858607530593872}\n"
     ]
    }
   ],
   "source": [
    "# The documents retrieved by the retriever:\n",
    "print(len(sources))\n",
    "print(sources[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00031919999999999995\n"
     ]
    }
   ],
   "source": [
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advanced-llm-workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
