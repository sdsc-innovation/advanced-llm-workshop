{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this hands-on we will use the `smolagents` library developed by HuggingFace. We use this library due to its simplicity, support for any LLM posted on HuggingFace Hub and its integration of Code Agents (more on that later).\n",
    "\n",
    "<img src=\"https://camo.githubusercontent.com/c6efa99360afde7cf829dff3cad81e56573658c1843464dff1fbb30a8f63b082/68747470733a2f2f68756767696e67666163652e636f2f64617461736574732f68756767696e67666163652f646f63756d656e746174696f6e2d696d616765732f7265736f6c76652f6d61696e2f736d6f6c6167656e74732f736d6f6c6167656e74732e706e67\" alt=\"drawing\" width=\"400\"/>\n",
    "\n",
    "[Smolagents Documentation](https://huggingface.co/docs/smolagents/en/index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this hands-on we will:\n",
    "- Understand why it's helpful to have agentic capabilities\n",
    "- Understand how to use the `smolagents` library\n",
    "- Understand the difference between a Tool Calling Agent and a Code Agent\n",
    "- Implement a custom Agent leveraging the RAG pipeline that we implemented before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up the environment\n",
    "\n",
    "We will use `gpt-4.1-mini` as our LLM for this hands-on. We could also use any model available on HuggingFace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r ../../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import LiteLLMModel\n",
    "from IPython.display import display_markdown\n",
    "\n",
    "model = LiteLLMModel(model_id=\"gpt-4.1-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_agent_cost(agent, model_name=\"gpt-4.1-mini\"):\n",
    "    if model_name == \"gpt-4o-mini\":\n",
    "        input_token_price = 0.15 / 1000000\n",
    "        output_token_price = 0.6 / 1000000\n",
    "    elif model_name == \"gpt-4o\":\n",
    "        input_token_price = 2.5 / 1000000\n",
    "        output_token_price = 10 / 1000000        \n",
    "    elif model_name == \"gpt-4.1-mini\":\n",
    "        input_token_price = 0.40 / 1000000\n",
    "        output_token_price = 1.6 / 1000000 \n",
    "    return (\n",
    "        input_token_price * agent.monitor.get_total_token_counts()[\"input\"]\n",
    "        + output_token_price * agent.monitor.get_total_token_counts()[\"output\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Let's create our first Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Tool Calling Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import ToolCallingAgent\n",
    "\n",
    "# This is as simple as\n",
    "agent = ToolCallingAgent(\n",
    "    tools=[],\n",
    "    model=model,\n",
    "    verbosity_level=0,\n",
    "    description=\"An agent that is capable of searching the web\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agent.run(\"What can you do?\")\n",
    "display_markdown(output, raw=True)\n",
    "print(\"Cost of the agent: \", compute_agent_cost(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so our agent says that it can help us answering questions. Let's see how it goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agent.run(\n",
    "    \"Can you visit https://www.swissinfo.ch/eng/ and tell me what are recent news?\"\n",
    ")\n",
    "display_markdown(output, raw=True)\n",
    "print(\"Cost of the agent: \", compute_agent_cost(agent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.write_memory_to_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I guess we forgot to give tools to our agent. Let's add a websearch tool. We can use the one provided by default by the smollagents library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import VisitWebpageTool\n",
    "\n",
    "visit_webpage_tool = VisitWebpageTool()\n",
    "agent = ToolCallingAgent(\n",
    "    tools=[visit_webpage_tool],\n",
    "    model=model,\n",
    "    verbosity_level=0,\n",
    "    description=\"An agent that is capable of searching the web\",\n",
    ")\n",
    "agent.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agent.run(\n",
    "    \"Can you visit https://www.swissinfo.ch/eng/ and tell me what are recent news?\"\n",
    ")\n",
    "display_markdown(output, raw=True)\n",
    "print(\"Cost of the agent: \", compute_agent_cost(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So now we have an agent that can answer questions using the LLM and also search the web for us.\n",
    "#### Let's see what the agents does behind the scene."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.write_memory_to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's print the system prompt\n",
    "print(\"\"\"\"\"\", agent.system_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A tool is an atomic function to be used by an agent. To be used by an LLM, it also needs a few attributes that constitute its API and will be used to describe to the LLM how to call this tool:\n",
    "\n",
    "    A name\n",
    "    A description\n",
    "    Input types and descriptions\n",
    "    An output type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library provide a list of default tools: https://github.com/huggingface/smolagents/blob/28cfef22389a2830176b48be9fcc3e3d5793b87b/src/smolagents/default_tools.py#L102\n",
    "\n",
    "- PythonInterpreterTool\n",
    "- FinalAnswerTool\n",
    "- UserInputTool\n",
    "- DuckDuckGoSearchTool\n",
    "- GoogleSearchTool\n",
    "- VisitWebpageTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `smolagents` library, there are two ways of declaring tool. Using the `@tool` decorator or using the `Tool` class.\n",
    "\n",
    "The `@tool` decorator is a more concise way of declaring a tool, but it is less flexible than the `Tool` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Defining a Tool as a Python Class\n",
    "\n",
    "In this class, we define:\n",
    "\n",
    "- `name`: The tool’s name.\n",
    "- `description`: A description used to populate the agent’s system prompt.\n",
    "- `inputs`: A dictionary with keys type and description, providing information to help the Python interpreter process inputs.\n",
    "- `output_type`: Specifies the expected output type.\n",
    "- `forward`: The method containing the inference logic to execute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import Tool\n",
    "\n",
    "\n",
    "class Sum(Tool):\n",
    "    name = \"sum\"\n",
    "    description = \"This is a tool that can add two numbers. It returns the sum of the two numbers.\"\n",
    "    inputs = {\n",
    "        \"number_1\": {\"type\": \"number\", \"description\": \"The first number to add.\"},\n",
    "        \"number_2\": {\"type\": \"number\", \"description\": \"The second number to add.\"},\n",
    "    }\n",
    "    output_type = \"number\"\n",
    "\n",
    "    def forward(self, number_1: float, number_2: float) -> float:\n",
    "        return number_1 + number_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_tool = Sum()\n",
    "agent = ToolCallingAgent(\n",
    "    tools=[sum_tool],\n",
    "    model=model,\n",
    ")\n",
    "agent.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agent.run(\"sum 3 4\")\n",
    "display_markdown(output, raw=True)\n",
    "print(\"Cost of the agent: \", compute_agent_cost(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The @tool Decorator\n",
    "\n",
    "Using this approach, we define a function with:\n",
    "\n",
    "- **A clear and descriptive function name** that helps the LLM understand its purpose.\n",
    "- **Type hints for both inputs and outputs** to ensure proper usage.\n",
    "- **A detailed description**, including an Args: section where each argument is explicitly described. These descriptions provide valuable context for the LLM, so it’s important to write them carefully."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def sum_tool(number_1: float, number_2: float) -> float:\n",
    "    \"\"\"\n",
    "    This is a tool that can add two numbers. It returns the sum of the two numbers.\n",
    "\n",
    "    Args:\n",
    "        number_1: The first number to add.\n",
    "        number_2: The second number to add.\n",
    "    \"\"\"\n",
    "    return number_1 + number_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = ToolCallingAgent(\n",
    "    tools=[sum_tool],\n",
    "    model=model,\n",
    ")\n",
    "agent.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agent.run(\"sum 3 4\")\n",
    "display_markdown(output, raw=True)\n",
    "print(\"Cost of the agent: \", compute_agent_cost(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code Agent vs Tool Calling Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "\n",
    "today = date.today()\n",
    "current_date = today.strftime(\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import DuckDuckGoSearchTool\n",
    "\n",
    "web_search = DuckDuckGoSearchTool()\n",
    "agent = ToolCallingAgent(\n",
    "    model=model,\n",
    "    tools=[sum_tool, web_search],\n",
    "    verbosity_level=1,\n",
    "    max_steps=10,\n",
    ")\n",
    "agent.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agent.run(\n",
    "    f\"You are an agent that can study financial market. Today's date is {current_date}. \"\n",
    "    + \"What is the gain that Nvidia stock made in the last week?\",\n",
    "    reset=True,\n",
    ")\n",
    "display_markdown(output, raw=True)\n",
    "print(\"Cost of the agent: \", compute_agent_cost(agent, model.model_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent\n",
    "\n",
    "agent = CodeAgent(\n",
    "    model=model,\n",
    "    add_base_tools=False,\n",
    "    tools=[sum_tool, web_search],\n",
    "    verbosity_level=1,\n",
    "    max_steps=10,\n",
    ")\n",
    "agent.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agent.run(\n",
    "    f\"You are an agent that can study financial market. Today's date is {current_date}. \"\n",
    "    + \"What is the gain that Nvidia stock made in the last week?\",\n",
    "    reset=True,\n",
    ")\n",
    "display_markdown(output, raw=True)\n",
    "print(\"Cost of the agent: \", compute_agent_cost(agent, model.model_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Hierarchy / MultiAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to use a multi-agent system, where multiple agents can be used to solve a problem. This is useful when the problem is too complex for a single agent to solve. In this case, the agents can communicate with each other to solve the problem.\n",
    "\n",
    "Another advantage is context size, as a single agent will store the full history of the steps, while a multi-agent system will store only the history of the steps of the agent that is currently active."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import CodeAgent, DuckDuckGoSearchTool\n",
    "\n",
    "\n",
    "web_agent = CodeAgent(\n",
    "    tools=[DuckDuckGoSearchTool()],\n",
    "    model=model,\n",
    "    add_base_tools=False,\n",
    "    name=\"information_retriever_agent\",\n",
    "    description=\"An agent that can be called to run web search to obtain information. Call it as a function using the **task** argument.\",\n",
    "    verbosity_level=1,\n",
    ")\n",
    "\n",
    "manager_agent = CodeAgent(\n",
    "    tools=[sum_tool],\n",
    "    model=model,\n",
    "    managed_agents=[web_agent],\n",
    "    verbosity_level=1,\n",
    "    description=\"An agent that manages other agent.\",\n",
    "    max_steps=10,\n",
    ")\n",
    "\n",
    "manager_agent.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = manager_agent.run(\n",
    "    f\"You are an agent that can study financial market. Today's date is {current_date}. \"\n",
    "    + \"What is the gain that Nvidia stock made in the last week?\",\n",
    "    reset=True,\n",
    ")\n",
    "display_markdown(output, raw=True)\n",
    "print(\"Cost of the agent: \", compute_agent_cost(manager_agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Your Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smolagents import (\n",
    "    GradioUI,\n",
    ")\n",
    "\n",
    "web_agent = CodeAgent(\n",
    "    tools=[DuckDuckGoSearchTool(), VisitWebpageTool()],\n",
    "    model=model,\n",
    "    name=\"information_retriever_agent\",\n",
    "    description=\"An agent that can be called to run web search to obtain information. Call it as a function using the **task** argument.\",\n",
    "    verbosity_level=0,\n",
    ")\n",
    "\n",
    "manager_agent = CodeAgent(\n",
    "    name=\"ManagerAgent\",\n",
    "    tools=[],\n",
    "    model=model,\n",
    "    managed_agents=[web_agent],\n",
    "    verbosity_level=0,\n",
    "    description=\"An agent that manages other agent.\",\n",
    "    max_steps=10,\n",
    ")\n",
    "\n",
    "GradioUI(manager_agent).launch(\n",
    "    share=True\n",
    ")  # This is necessary to make it work in Renku but be careful"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# !!! Do not forget to stop the process of the previous cell before executing the next ones !!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Another Multi Agent Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create:\n",
    "\n",
    "- an agent that can read a document and summarize it\n",
    "\n",
    "- an agent that can search the web\n",
    "\n",
    "- a manager agent that handle both previous agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from helpers.data_processing import SimpleChunker, PDFExtractor\n",
    "\n",
    "\n",
    "@tool\n",
    "def read_pdf_tool(pdf_file_path: str) -> str:\n",
    "    \"\"\"\n",
    "    This tool reads a PDF file and returns the text content of the PDF file.\n",
    "\n",
    "    Args:\n",
    "        pdf_file_path: The path to the PDF file.\n",
    "    \"\"\"\n",
    "    response, text, images = PDFExtractor().extract_text_and_images(pdf_file_path)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = read_pdf_tool(\"../../data/hypoxy_stat_1page.pdf\")\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_read_pdf = CodeAgent(\n",
    "    name=\"read_pdf_agent\",\n",
    "    description=\"Reads and summarize a PDF file. Call it as a function using the **task** argument.\",\n",
    "    tools=[read_pdf_tool],\n",
    "    add_base_tools=True,\n",
    "    model=model,\n",
    "    verbosity_level=1,\n",
    ")\n",
    "\n",
    "agent_web_search = CodeAgent(\n",
    "    name=\"web_search_agent\",\n",
    "    description=\"Runs web searches for you. Call it as a function using the **task** argument.\",\n",
    "    tools=[DuckDuckGoSearchTool(), visit_webpage_tool],\n",
    "    add_base_tools=True,\n",
    "    model=model,\n",
    "    verbosity_level=1,\n",
    ")\n",
    "\n",
    "agent = CodeAgent(\n",
    "    name=\"medical_agent\",\n",
    "    tools=[],\n",
    "    model=model,\n",
    "    add_base_tools=False,\n",
    "    managed_agents=[agent_read_pdf, agent_web_search],\n",
    "    verbosity_level=1,\n",
    ")\n",
    "\n",
    "agent.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = agent.run(\n",
    "    \"Your task is the following: \"\n",
    "    + \"Can you read the PDF file at '../../data/hypoxy_stat_1page.pdf' and tell me what it is about? Also, can you give me the wikipedia definition of the area of research?\",\n",
    "    reset=True,\n",
    ")\n",
    "display_markdown(output, raw=True)\n",
    "print(\"Cost of the agent: \", compute_agent_cost(agent))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Create your own RAG Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/beating_gaia/classical_vs_agentic_rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will create a simple agent that can answer questions on a knowledge base, AKA a **RAG agent**.\n",
    "\n",
    "1. Define a tool that retrieve documents from a knowledge base\n",
    "2. Define an agent that uses the tool to retrieve documents and answer questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers.constants_and_data_classes import Chunk\n",
    "from helpers.data_processing import SimpleChunker, PDFExtractorAPI\n",
    "from helpers.embedding import (\n",
    "    OpenAITextEmbeddings,\n",
    "    compute_openai_large_embedding_cost,\n",
    ")\n",
    "from helpers.vectorstore import (\n",
    "    ChromaDBVectorStore,\n",
    "    VectorStoreRetriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../../data\"\n",
    "\n",
    "pdf_files = [\n",
    "    \"Explainable_machine_learning_prediction_of_edema_a.pdf\",\n",
    "    \"Modeling tumor size dynamics based on real‐world electronic health records.pdf\",\n",
    "]\n",
    "example_pdf_file = \"Explainable_machine_learning_prediction_of_edema_a.pdf\"\n",
    "example_pdf_path = os.path.join(data_folder, example_pdf_file)\n",
    "\n",
    "vector_store_collection = \"text_collection\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_extractor = PDFExtractor()\n",
    "_, text, _ = data_extractor.extract_text_and_images(example_pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_metadata = {\"source_text\": example_pdf_file}\n",
    "\n",
    "text_chunker = SimpleChunker(max_chunk_size=1000)\n",
    "\n",
    "chunks = text_chunker.chunk_text(text, file_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = OpenAITextEmbeddings()\n",
    "embeddings = embedding_model.get_embedding([chunk.content for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = ChromaDBVectorStore(vector_store_collection)\n",
    "vector_store.insert_chunks(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = VectorStoreRetriever(embedding_model, vector_store)\n",
    "results = retriever.retrieve(\"Who are the authors of the paper=\", 5)\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Toolify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the retriever tool\n",
    "@tool\n",
    "def retriever_tool(query: str, number_of_chunks: int) -> list:\n",
    "    ## Fill the docstring here\n",
    "\n",
    "    return retriever.retrieve(query, number_of_chunks)\n",
    "\n",
    "\n",
    "# Create the CodeAgent with the tool\n",
    "rag_agent = CodeAgent(tools=[retriever_tool], model=model)\n",
    "rag_agent.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the retriever tool\n",
    "@tool\n",
    "def retriever_tool(query: str, number_of_chunks: int) -> list:\n",
    "    \"\"\"\n",
    "    This is a tool that can search a document and extract the related information based on the query given. It returns a list of string\n",
    "    Only use this tool if necessary to answer the query otherwise rely on your internal knowledge.\n",
    "\n",
    "    Args:\n",
    "        query: The user query\n",
    "        number_of_chunks: number of chunks to return, by default it's 5.\n",
    "    \"\"\"\n",
    "\n",
    "    return retriever.retrieve(query, number_of_chunks)\n",
    "\n",
    "\n",
    "# Create the CodeAgent with the tool\n",
    "rag_agent = CodeAgent(tools=[retriever_tool], model=model)\n",
    "rag_agent.visualize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the agent\n",
    "output = rag_agent.run(\n",
    "    \"According to SHAP analysis, which factors were the most influential in predicting higher-grade edema (Grade 2+)?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = rag_agent.run(\"What is the highest court of the USA?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Make it a multi-agent system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we built a RAG agent, we will improve it by adding a web search tool to it. This way, if the agent can't find the answer in the knowledge base, it will search the web for it.\n",
    "\n",
    "However, we will transform our agent into a multi-agent system. This way, we will have one agent responsible for answering questions using the knowledge base and another agent responsible for searching the web.\n",
    "\n",
    "1. Define a tool that searches the web\n",
    "2. Define a new agent that uses the web search tool\n",
    "3. Create a multi-agent system that uses both agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_rag_agent = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#\n",
    "from smolagents import DuckDuckGoSearchTool\n",
    "\n",
    "web_search_agent = CodeAgent(\n",
    "    name=\"web_search_agent\",\n",
    "    description=\"Runs web searches for you. Call it as a function using the **task** argument.\",\n",
    "    tools=[DuckDuckGoSearchTool(), visit_webpage_tool],\n",
    "    add_base_tools=True,\n",
    "    model=model,\n",
    "    verbosity_level=1,\n",
    ")\n",
    "\n",
    "rag_agent = CodeAgent(\n",
    "    name=\"medical_literature_agent\",\n",
    "    description=\"Retrieve information from medical litterature. Call it as a function using the **task** argument.\",\n",
    "    tools=[retriever_tool],\n",
    "    model=model,\n",
    ")\n",
    "\n",
    "multi_rag_agent = CodeAgent(\n",
    "    tools=[],\n",
    "    model=model,\n",
    "    add_base_tools=False,\n",
    "    managed_agents=[rag_agent, web_search_agent],\n",
    "    verbosity_level=1,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the agent\n",
    "output = multi_rag_agent.run(\n",
    "    \"According to SHAP analysis, which factors were the most influential in predicting higher-grade edema (Grade 2+)?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = multi_rag_agent.run(\"What is the current price of Nvidia stock?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
